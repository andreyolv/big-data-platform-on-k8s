apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: airflow
  namespace: airflow
spec:
  interval: 5m
  chart:
    spec:
      chart: airflow
      version: '1.7.0'
      sourceRef:
        kind: HelmRepository
        name: apache-airflow
#  values:
#    executor: "KubernetesExecutor"
#    images:
#      airflow:
#        pullPolicy: Always
#        repository: raizenanalyticsdev.azurecr.io/airflow-base
#        tag: 'v2.3.6-slim'
#    multiNamespaceMode: true
#    dags:
#      persistence:
#        enabled: true
#        existingClaim: airflow-azure-fileshare-dags
#    logs:
#      persistence:
#        enabled: true
#        existingClaim: airflow-azure-fileshare-logs
#    scheduler:
#      replicas: 2
#      resources:
#        requests:
#          cpu: 500m
#          memory: 512Mi
#      env:
#        - name: AIRFLOW__CORE__EXECUTOR
#          value: raizen.custom_kubernetes_executor.CustomKubernetesExecutor
#        - name: ENVIRONMENT
#          value: prod
#        - name: AIRFLOW_ENV
#          value: QA
#        - name: MEMCACHE_HOST
#          value: memcache.airflow.svc.cluster.local
#        - name: AIRFLOW__CORE__PARALLELISM
#          value: '64'
#        - name: AIRFLOW__SCHEDULER__SCHEDULE_AFTER_TASK_EXECUTION
#          value: 'False'
#        - name: AIRFLOW__SCHEDULER__PARSING_PROCESSES
#          value: '2'
#    webserver:
#      resources:
#        requests:
#          cpu: 500m
#          memory: 512Mi
#      env:
#        - name: AIRFLOW__CORE__EXECUTOR
#          value: raizen.custom_kubernetes_executor.CustomKubernetesExecutor
#        - name: AIRFLOW__API__AUTH_BACKENDS
#          value: airflow.api.auth.backend.basic_auth
#        - name: ENVIRONMENT
#          value: prod
#        - name: AIRFLOW_ENV
#          value: QA
#        - name: MEMCACHE_HOST
#          value: memcache.airflow.svc.cluster.local
#    workers:
#      env:
#        - name: AIRFLOW_ENV
#          value: QA
#        - name: ENVIRONMENT
#          value: prod
#        - name: MEMCACHE_HOST
#          value: memcache.airflow.svc.cluster.local
#      serviceAccount:
#        create: false
#      podAnnotations:
#        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
#    secret:
#    - envName: "AZURE_STORAGE_ACCESS_KEY"
#      secretName: "azure-storage-mlflow-secrets"
#      secretKey: "storage-access-key"
#    dagProcessor:
#      enabled: true
#      replicas: 2
#      livenessProbe:
#        command:
#        - sh
#        - -c
#        - |
#          CONNECTION_CHECK_MAX_COUNT=0 AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR exec /entrypoint \
#          airflow jobs check --job-type SchedulerJob --allow-multiple --limit 100
#      env:
#        - name: AIRFLOW__SCHEDULER__PARSING_PROCESSES
#          value: '5'
#        - name: AIRFLOW__LOGGING__LOGGING_LEVEL
#          value: 'DEBUG'
#    postgresql:
#      enabled: false
#    data:
#      metadataSecretName: airflow-db-metadata
#    webserverSecretKeySecretName: airflow-webserver-secret
#    fernetKeySecretName: airflow-fernet-key
#    airflowConfigAnnotations:
#      replicator.v1.mittwald.de/replicate-to-matching: airflow=yes
#    ingress:
#      web:
#        enabled: true
#        host: airflow.qa.raizen.ai
#        ingressClassName: nginx
#        pathType: Prefix
#        tls:
#          enabled: true
#          secretName: raizen-ai-qa-tls
#    registry:
#      secretName: 'acr-secret'
#    # createUserJob:
#    #   useHelmHooks: false
#    # migrateDatabaseJob:
#    #   useHelmHooks: false